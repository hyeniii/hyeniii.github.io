---
layout: page
title: Fraud detection model pipeline
description: Building a Machine Learning Pipeline for Fraud Detection
img:
importance: 1
category: fun
---

<div class="col-sm mt-3 mt-md-0">
    {% include figure.html path="assets/img/12.jpg" title="credit card fraud image" class="img-fluid rounded z-depth-1" style="max-width: 50%;"%}
</div>


## Introduction

This project develops a flexible machine learning pipeline tailored for detecting credit card fraud. Its core feature is the ability to train various models through configurable YAML files, allowing users to test different approaches easily. Integrated with MLflow, the pipeline tracks and manages training experiments, aiding in the comparison and evaluation of diverse models.

A significant aspect of this pipeline is its capability to handle imbalanced data, a common challenge in fraud detection. Users can experiment with different sampling methods to balance the dataset, ensuring more accurate and reliable model performance. This flexibility, combined with comprehensive experiment tracking, positions the pipeline as a versatile tool in the fight against credit card fraud.

## Project setup
The project uses a variety of tools and libraries, including 
- pandas for data manipulation, 
- scikit-learn for machine learning, 
- MLflow for experiment tracking,
- joblib for model serialization

The configuration is managed using YAML files, offering a flexible and dynamic way to handle various parameters.

Here is an example of the config yaml file...
```yaml
experiment_name: "RandomForestClassifier hp tuning"
data_path: "data/creditcard.csv"
target: "Class"

model:
  class: "RandomForestClassifier"
  module: "sklearn.ensemble"
  params:
    n_estimators: [100, 500]
    max_depth: [10, 50]
  save_path: "artifacts/model/rf_model.joblib"

preprocessing:
  sampler:
    class: "RandomOverSampler"
    module: "imblearn.over_sampling"
  scaler:
    class: "StandardScaler"
    module: "sklearn.preprocessing"
```
Experimenter can simply change preprocessing and modeling methods by changing the corresponding methods in the config file and run the experiment.

### Imbalance in Dataset: Strategies and Considerations


<div class="col-sm-5 mt-3 mt-md-0" style="float: left; margin-right: 20px;" >
    {% include figure.html path="assets/img/imbalance.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
</div>

In machine learning, especially in problems like credit card fraud detection, class imbalance poses a significant challenge. The imbalance occurs when one class (e.g., fraudulent transactions) is vastly outnumbered by another (e.g., legitimate transactions). This imbalance can lead to models that are biased towards the majority class, often at the expense of poorly predicting the minority class, which is usually the class of interest.

##### Strategies for Handling Imbalance

- **Class Weights**: For models that support the class_weight parameter (such as many in scikit-learn), assigning a higher weight to the minority class helps counterbalance its underrepresentation. In our pipeline, we've integrated `class_weight='balanced'` for such models. This approach effectively tells the model to "pay more attention" to the minority class, which is crucial in fraud detection where failing to detect fraud (a false negative) can be very costly.

- **Sampling Methods**: When class weights are not an option, or to explore different approaches, we can use sampling methods. These methods adjust the dataset before training the model. We've provided options for:
    - **Undersampling**: Reducing the number of instances in the majority class.
    - **Oversampling**: Increasing the number of instances in the minority class.
    - **SMOTE (Synthetic Minority Over-sampling Technique)**: Creating synthetic instances of the minority class.

##### The Debate Around SMOTE

While SMOTE is a popular and powerful method to handle imbalanced datasets, it's not without its critics. Some concerns include:

- **Distorted Data Space**: Synthetic points generated by SMOTE may not represent the true data distribution, potentially leading the model to learn incorrect patterns.

- **Noise**: If the minority class has outliers, SMOTE may amplify these outliers by creating more synthetic instances around them.

### Results and Comparisons

#### ROC Curves and Recall Comparisons
[Include ROC curve plots and recall values]

#### Precision-Recall Curves
[Include precision-recall curve plots]

#### Confusion Matrices
[Present confusion matrices for each model]

#### F1 Scores and AUC
[Table or chart comparing F1 scores and AUC values]

#### Model Efficiency
[Discuss training and prediction times]

#### Feature Importance Analysis
[Insights from feature importance, if applicable]

#### Summary Table
[A comprehensive table summarizing all key metrics for each model]

#### Discussion of Results
[Interpretation and insights from the above analyses]

